{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scv import binvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "config = {\n",
    "  'block': None, # Mark a block of data with a specified color. Format: hexstartaddr:hexendaddr[:hexcolor].\n",
    "  'color': 'hilbert', # Color map to use. Options: class, hilbert, entropy, gradient.\n",
    "  'map': 'hilbert', # Pixel layout map. Can be any supported curve.\n",
    "  'namesuffix': '', # Suffix for generated file names. Ignored if destination is specified.\n",
    "  'progress': False, # Show progress bar.\n",
    "  'size': 256, # Image size in pixels.\n",
    "  'type': \"square\", # Image aspect ratio - square (1x1) or unrolled (1x4). Options: square, unrolled.\n",
    "  'quiet': False, # Suppress all output.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pkl(pkl_input_file, img_output_path, img_output_file):\n",
    "  print(f'[INFO] Processing {pkl_input_file}')\n",
    "  \n",
    "  if not os.path.exists(img_output_path):\n",
    "    os.makedirs(img_output_path)\n",
    "  \n",
    "  img_output_file = os.path.join(img_output_path, img_output_file)\n",
    "  \n",
    "  # Read binary file\n",
    "  with open(pkl_input_file, 'rb') as f:\n",
    "    data = f.read()\n",
    "  \n",
    "  # if not os.path.exists(img_output_file):\n",
    "  #   os.makedirs(img_output_file)\n",
    "\n",
    "  # Block specification\n",
    "  block = None\n",
    "  if config['block']:\n",
    "    parts = config['block'].split(':')\n",
    "    if len(parts) not in [2, 3]:\n",
    "      raise ValueError(\"Invalid block specification.\")\n",
    "    s, e = int(parts[0], 16), int(parts[1], 16)\n",
    "    if len(parts) == 3:\n",
    "      c = binvis.draw.parseColor(parts[2])\n",
    "    else:\n",
    "      c = [255, 0, 0]\n",
    "    block = (s, e, c)\n",
    "    \n",
    "  # Color map\n",
    "  if config['color'] not in ['class', 'hilbert', 'entropy', 'gradient']:\n",
    "    raise ValueError(\"Invalid color map.\")\n",
    "  color = config['color']\n",
    "\n",
    "  csource_map = {\n",
    "    'class': binvis.ColorClass(data, block),\n",
    "    'hilbert': binvis.ColorHilbert(data, block),\n",
    "    'gradient': binvis.ColorGradient(data, block),\n",
    "    'entropy': binvis.ColorEntropy(data, block),\n",
    "  }\n",
    "  csource = csource_map[color]\n",
    "\n",
    "  # Progress bar\n",
    "  if config['progress']:\n",
    "    print(\"Generating image...\")\n",
    "    print(f\"Destination: {img_output_file}\")\n",
    "\n",
    "  if config['quiet'] or config['progress']:\n",
    "    prog = binvis.progress.Dummy()\n",
    "  else:\n",
    "    prog = binvis.progress.Progress(None)\n",
    "\n",
    "  # Type specification\n",
    "  if config['type'] == 'unrolled':\n",
    "    binvis.drawmap_unrolled(config['map'], config['size'], csource, img_output_file, prog)\n",
    "  elif config['type'] == 'square':\n",
    "    binvis.drawmap_square(config['map'], config['size'], csource, img_output_file, prog)\n",
    "  prog.clear()\n",
    "  \n",
    "  print(f'[SUCCESS] Image saved to {img_output_file} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(input_folder, output_folder):\n",
    "  print(f'[INFO] Processing folder: {input_folder}')\n",
    "  # Get all .pkl files in the folder\n",
    "  if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "  label_name = input_folder.split('/')[-2]\n",
    "  \n",
    "  if len(glob(os.path.join(output_folder, label_name, '*.png'))) >= 200:\n",
    "    print(f'[INFO] {label_name} images already exists in {output_folder} \\n')\n",
    "    return\n",
    "  else:\n",
    "    pkl_files = glob(os.path.join(input_folder, '*.pkl'))\n",
    "    for fkl_file in pkl_files:\n",
    "      img_name = fkl_file.split('/')[-1].split('.')[0]\n",
    "      output_img = os.path.join(output_folder, label_name, f'{img_name}.png')\n",
    "      # Skip if image already exists\n",
    "      if os.path.exists(output_img) or len(glob(os.path.join(output_folder, label_name, '*.png'))) >= 200:\n",
    "        continue\n",
    "      else:\n",
    "        process_pkl(fkl_file, os.path.join(output_folder, label_name), f'{img_name}.png')\n",
    "  \n",
    "    print(f'[SUCCESS] {label_name} images saved to {output_folder} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_thread_process(folders_paths, output_folder, num_workers=4):\n",
    "  print(f'[INFO] Processing {len(folders_paths)} folders with {num_workers} workers')\n",
    "  # Use ThreadPoolExecutor for concurrent processing with specified number of workers\n",
    "  with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = []\n",
    "    for folder_path in folders_paths:\n",
    "      future = executor.submit(process_folder, folder_path, output_folder)\n",
    "      futures.append(future)\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    for future in futures:\n",
    "      future.result()\n",
    "      \n",
    "  print(f'[SUCCESS] All folders processed and images saved to {output_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|>                                        | 0:00:13 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Image saved to ./img_dataset/vsftpd2/batch_1133_33990-34020.png \n",
      "\n",
      "[INFO] Processing ./bin_dataset/vsftpd2/batch_735_22050-22080.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|>                                        | 0:00:13 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Image saved to ./img_dataset/vsftpd2/batch_735_22050-22080.png \n",
      "\n",
      "[INFO] Processing ./bin_dataset/vsftpd2/batch_350_10500-10530.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|>                                        | 0:00:13 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Image saved to ./img_dataset/vsftpd2/batch_350_10500-10530.png \n",
      "\n",
      "[INFO] Processing ./bin_dataset/vsftpd2/batch_228_6840-6870.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|>                                        | 0:00:12 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Image saved to ./img_dataset/vsftpd2/batch_228_6840-6870.png \n",
      "\n",
      "[INFO] Processing ./bin_dataset/vsftpd2/batch_150_4500-4530.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Image saved to ./img_dataset/vsftpd2/batch_150_4500-4530.png \n",
      "\n",
      "[SUCCESS] vsftpd2 images saved to ./img_dataset \n",
      "\n",
      "[SUCCESS] All folders processed and images saved to ./img_dataset\n"
     ]
    }
   ],
   "source": [
    "bin_dataset_folder = \"./bin_dataset\"\n",
    "\n",
    "# List all subfolders in the bin_dataset folder\n",
    "subfolders = glob(os.path.join(bin_dataset_folder, '*/'))\n",
    "\n",
    "# Process folders concurrently with 4 workers\n",
    "multi_thread_process(subfolders, './img_dataset', num_workers=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
